{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "base_data= json.loads(open('base_data.json').read())\n",
    "\n",
    "words=pickle.load(open('words.pkl','rb'))\n",
    "classes=pickle.load(open('classes.pkl','rb'))\n",
    "model=load_model('AI_chatbot.h5')\n",
    "\n",
    "def clean_up_sent(sent):\n",
    "    sent_words=nltk.word_tokenize(sent)\n",
    "    sent_words=[lemma.lemmatize(word) for word in sent_words]\n",
    "    return sent_words\n",
    "\n",
    "def bag_of_words(sent):\n",
    "    sentence_word= clean_up_sent(sent)\n",
    "    bag=[0]*len(words)\n",
    "    for w in sentence_word:\n",
    "        for i, word in enumerate(words):\n",
    "            if word==w:\n",
    "                bag[i]=1\n",
    "    return np.array(bag)\n",
    "\n",
    "def predict_class(sentence):\n",
    "    bow= bag_of_words(sentence)\n",
    "    res=model.predict(np.array([bow]))[0]\n",
    "    error_threshold= 0.25\n",
    "    result= [[i,r] for i,r in enumerate(res) if  r> error_threshold]\n",
    "\n",
    "    result.sort(key=lambda x: x[1], reverse= True)\n",
    "    return_list = []\n",
    "    for r in result:\n",
    "        return_list.append({'intent': classes[r[0]],\"probability\":str(r[1])})\n",
    "    return return_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bot is running Now...!\n",
      "hello\n",
      "how is your day\n",
      "great\n",
      "lets talk more..\n",
      "who are you\n",
      "i am a chatbot..!\n",
      "what do you do\n",
      "data science is work field..!\n",
      "hi\n",
      "Good morning..\n",
      "do you have a boyfriend\n",
      "machines dont love they compute\n",
      "coffie with me\n",
      "i am sigle\n",
      "your name\n",
      "my owner named me as AI-chatBot\n",
      "you are food\n",
      "my owner named me as AI-chatBot\n",
      "you are good\n",
      "all for you\n",
      "you are great you know\n",
      "all for you\n",
      "love you\n",
      "don't have time for love\n",
      "why so rude\n",
      "come again\n",
      "goodbye\n",
      "nice talking to you come again\n"
     ]
    }
   ],
   "source": [
    "def get_response(intent_list, intent_json):\n",
    "    tag=intent_list[0][\"intent\"]\n",
    "    list_of_intents= intent_json[\"base_data\"]\n",
    "    for i in list_of_intents:\n",
    "        if i['tag']==tag:\n",
    "            result = random.choice(i[\"responses\"])\n",
    "            break\n",
    "    return result\n",
    "\n",
    "print(\" bot is running Now...!\")\n",
    "\n",
    "while True:\n",
    "    message= input(\"\")\n",
    "    ints= predict_class(message)\n",
    "    res=get_response(ints,base_data)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
